{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Dependencies (if needed)\n",
        "!pip install xgboost joblib scikit-learn pandas numpy\n",
        "\n",
        "# Step 2: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Step 3: Load Dataset\n",
        "df = pd.read_csv(\"/content/cleaned_data (1).csv\")\n",
        "\n",
        "# Step 4: Handle Missing Values (if any)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Step 5: Encode Categorical Features using OneHotEncoder (Updated Fix)\n",
        "categorical_cols = [\"State_Name\", \"District_Name\", \"Season\", \"Crop\"]\n",
        "onehot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)  # ‚úÖ FIXED HERE\n",
        "encoded_categorical = onehot_encoder.fit_transform(df[categorical_cols])\n",
        "\n",
        "# Step 6: Scale Numerical Features (Area)\n",
        "scaler = StandardScaler()\n",
        "df[\"Area\"] = scaler.fit_transform(df[[\"Area\"]])\n",
        "\n",
        "# Step 7: Define Features (X) and Target (y)\n",
        "X = np.hstack((encoded_categorical, df[[\"Crop_Year\", \"Area\"]].values))  # Combine encoded + numerical features\n",
        "y = df[\"Production\"]\n",
        "\n",
        "# Step 8: Split Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 9: Train XGBoost Model\n",
        "xgb_reg = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.1, max_depth=6)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "\n",
        "# Step 10: Model Evaluation\n",
        "y_pred = xgb_reg.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Performance:\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤ Score: {r2:.4f}\")\n",
        "\n",
        "# Step 11: Save the Model and Preprocessing Objects\n",
        "joblib.dump(xgb_reg, \"xgboost_production_model2.pkl\")  # Save trained model\n",
        "joblib.dump(onehot_encoder, \"onehot_encoder.pkl\")  # Save OneHotEncoder\n",
        "joblib.dump(scaler, \"scaler.pkl\")  # Save StandardScaler\n",
        "\n",
        "print(\"‚úÖ Model and encoders saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGPn9csup4Hi",
        "outputId": "4a910004-80ed-46d5-f345-71c7e5974ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Model Performance:\n",
            "RMSE: 5448071.57\n",
            "R¬≤ Score: 0.8140\n",
            "‚úÖ Model and encoders saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"/content/cleaned_data (1).csv\")\n",
        "\n",
        "# ‚úÖ Fix Area Scaling (Log Transformation)\n",
        "df[\"Log_Area\"] = np.log1p(df[\"Area\"])  # Log transformation ensures better learning\n",
        "\n",
        "# ‚úÖ Encode Categorical Features with OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "encoded_categorical = onehot_encoder.fit_transform(df[[\"State_Name\", \"District_Name\", \"Season\", \"Crop\"]])\n",
        "\n",
        "# Define Features & Target\n",
        "X = np.hstack((encoded_categorical, df[[\"Crop_Year\", \"Log_Area\"]].values))  # ‚úÖ Use Log_Area\n",
        "y = df[\"Production\"]\n",
        "\n",
        "# ‚úÖ Train-Test Split (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‚úÖ Train XGBoost Model\n",
        "xgb_reg = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=200, learning_rate=0.1, max_depth=6)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "\n",
        "# Step 10: Model Evaluation\n",
        "y_pred = xgb_reg.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Performance:\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤ Score: {r2:.4f}\")\n",
        "\n",
        "# Step 11: Save the Model and Preprocessing Objects\n",
        "'''joblib.dump(xgb_reg, \"xgboost_production_model2.pkl\")  # Save trained model\n",
        "joblib.dump(onehot_encoder, \"onehot_encoder.pkl\")  # Save OneHotEncoder\n",
        "joblib.dump(scaler, \"scaler.pkl\")  # Save StandardScaler'''\n",
        "\n",
        "# ‚úÖ Save Model and Encoders for Deployment\n",
        "'''joblib.dump(xgb_reg, \"xgboost_production_model.pkl\")\n",
        "joblib.dump(onehot_encoder, \"onehot_encoder.pkl\")'''\n",
        "\n",
        "print(\"üéØ Model training complete! Files saved: xgboost_production_model.pkl, onehot_encoder.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl_tycAbvOUF",
        "outputId": "1a1d00b3-9598-49cc-ecb7-46637c1a2c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "RMSE: 5359832.49\n",
            "R¬≤ Score: 0.8200\n",
            "üéØ Model training complete! Files saved: xgboost_production_model.pkl, onehot_encoder.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_csv(\"/content/cleaned_data (1).csv\")\n",
        "\n",
        "# Check Correlation\n",
        "correlation = df[[\"Area\", \"Production\"]].corr()\n",
        "print(\"Correlation between Area and Production:\\n\", correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNdePzWmxZRV",
        "outputId": "aa2d28ff-0a1e-47d2-a1ca-7c5bf28bf800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between Area and Production:\n",
            "                 Area  Production\n",
            "Area        1.000000    0.040545\n",
            "Production  0.040545    1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"/content/cleaned_data (1).csv\")\n",
        "\n",
        "# ‚úÖ Encode Categorical Features\n",
        "onehot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "encoded_categorical = onehot_encoder.fit_transform(df[[\"State_Name\", \"District_Name\", \"Season\", \"Crop\"]])\n",
        "\n",
        "# ‚úÖ Define Features & Target (Remove 'Area' completely)\n",
        "X = np.hstack((encoded_categorical, df[[\"Crop_Year\"]].values))  # ‚ùå Area is removed\n",
        "y = df[\"Production\"]\n",
        "\n",
        "# ‚úÖ Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‚úÖ Train XGBoost Model\n",
        "xgb_reg = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=500, learning_rate=0.05, max_depth=6)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "# Step 10: Model Evaluation\n",
        "y_pred = xgb_reg.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Performance:\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤ Score: {r2:.4f}\")\n",
        "\n",
        "'''# Step 11: Save the Model and Preprocessing Objects\n",
        "joblib.dump(xgb_reg, \"xgboost_production_model2.pkl\")  # Save trained model\n",
        "joblib.dump(onehot_encoder, \"onehot_encoder.pkl\")  # Save OneHotEncoder\n",
        "joblib.dump(scaler, \"scaler.pkl\")  # Save StandardScaler\n",
        "\n",
        "# ‚úÖ Save Model and Encoders for Deployment\n",
        "joblib.dump(xgb_reg, \"xgboost_production_model.pkl\")\n",
        "joblib.dump(onehot_encoder, \"onehot_encoder.pkl\")'''\n",
        "\n",
        "print(\"üéØ Model training complete! Files saved: xgboost_production_model.pkl, onehot_encoder.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJhu84FqyXlp",
        "outputId": "1691e26b-ce0f-4562-e8fc-18ccca1ddc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "RMSE: 6400077.53\n",
            "R¬≤ Score: 0.7433\n",
            "üéØ Model training complete! Files saved: xgboost_production_model.pkl, onehot_encoder.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"/content/cleaned_data (1).csv\")\n",
        "\n",
        "# ‚úÖ Convert Year into a Relative Feature\n",
        "df[\"Year_Diff\"] = df[\"Crop_Year\"] - df[\"Crop_Year\"].min()\n",
        "\n",
        "# ‚úÖ Add Crop Impact (Average Production per Crop)\n",
        "df[\"Crop_Avg_Production\"] = df.groupby(\"Crop\")[\"Production\"].transform(\"mean\")\n",
        "\n",
        "# ‚úÖ OneHot Encode Categorical Features (State, District, Season, Crop)\n",
        "onehot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "encoded_categorical = onehot_encoder.fit_transform(df[[\"State_Name\", \"District_Name\", \"Season\", \"Crop\"]])\n",
        "\n",
        "# ‚úÖ Scale Numerical Features\n",
        "scaler = StandardScaler()\n",
        "df[[\"Scaled_Year_Diff\", \"Scaled_Crop_Avg_Production\"]] = scaler.fit_transform(df[[\"Year_Diff\", \"Crop_Avg_Production\"]])\n",
        "\n",
        "# ‚úÖ Define Features & Target\n",
        "X = np.hstack((encoded_categorical, df[[\"Scaled_Year_Diff\", \"Scaled_Crop_Avg_Production\"]].values))\n",
        "y = df[\"Production\"]\n",
        "\n",
        "# ‚úÖ Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‚úÖ Train XGBoost Model\n",
        "xgb_reg = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=500, learning_rate=0.05, max_depth=6)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "\n",
        "# Step 10: Model Evaluation\n",
        "y_pred = xgb_reg.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Performance:\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤ Score: {r2:.4f}\")\n",
        "\n",
        "'''# Step 11: Save the Model and Preprocessing Objects\n",
        "joblib.dump(xgb_reg, \"xgboost_production_model2.pkl\")  # Save trained model\n",
        "joblib.dump(onehot_encoder, \"onehot_encoder.pkl\")  # Save OneHotEncoder\n",
        "joblib.dump(scaler, \"scaler.pkl\")  # Save StandardScaler\n",
        "\n",
        "# ‚úÖ Save Model and Encoders for Deployment\n",
        "joblib.dump(xgb_reg, \"xgboost_production_model.pkl\")\n",
        "joblib.dump(onehot_encoder, \"onehot_encoder.pkl\")\n",
        "joblib.dump(scaler, \"year_scaler.pkl\")  # Save scaler for numerical features'''\n",
        "\n",
        "print(\"üéØ Model training complete! Crop Name now affects predictions!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dW71-vB3pHT",
        "outputId": "6a3b765a-f98a-4daa-ea7f-4ed2776ac0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "RMSE: 6576824.57\n",
            "R¬≤ Score: 0.7289\n",
            "üéØ Model training complete! Crop Name now affects predictions!\n"
          ]
        }
      ]
    }
  ]
}